{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. How did we get to a single vector of activations in the CNNs used for MNIST in previous chapters? Why isn't that suitable for Imagenette?__\n",
    "\n",
    "We used enough stride 2 convs to ensure that the final layer has a activation map dimension of 1x1. Then we used nn.Flatten() to remove the 1x1 unit axes. This gives us a matrix of activations by batch. This method in MNIST assumed a starting image size of 28x28. \n",
    "\n",
    "This method is not suiable for Imagette because our images might be larger than 28x28.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. What do we do for Imagenette instead?__\n",
    "\n",
    "We use fully convolution neural networks. In these networks we take the average of activations across the convolutional grid. This will convert a grid of activations into a single activation per image.\n",
    "\n",
    "TODO: Does a FC network require a linear layer at the end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. What is \"adaptive pooling\"?__\n",
    "\n",
    "In average pooling you set the ks and the stride yourself. \n",
    "\n",
    "In adaptive average pooling you specify the output. The ks and stride are auto detected. It's less work for you.\n",
    "\n",
    "https://stackoverflow.com/questions/58692476/what-is-adaptive-average-pooling-and-how-does-it-work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. What is \"average pooling\"?__\n",
    "\n",
    "See above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. Why do we need `Flatten` after an adaptive average pooling layer?__\n",
    "\n",
    "The activation map has a unit dimension (1x1) after the adaptive average pooling layer. `nn.Flatten()` removes the unit axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6. What is a \"skip connection\"?__\n",
    "\n",
    "In a skip connection we do `x+conv2(conv1(x))`. The batchnorm has a gamma set to 0. As a result `x+conv2(conv1(x))` will be equal to `x` initially. So the network does nothing and returns the identity matrix.\n",
    "\n",
    "The parameters are then trained to make the skip connection more useful. (Kind of like a call option - the downside is limited to the original matrix in the upside is unlimited?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7. Why do skip connections allow us to train deeper models?__\n",
    "\n",
    "A resent is good at measuring Opportunity Cost. \n",
    "\n",
    "It measures the cost of doing nothing (returning the identity) vs the cost of doing something (passing the block through two conv layers with trainable weights). \n",
    "\n",
    "Sometimes doing nothing is a valid choice. In this case the network places less emphasis on the resblock - saving time and valuable compute.\n",
    "\n",
    "This allows us to train deeper models.\n",
    "\n",
    "TODO: check if this is right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__8. What does <<resnet_depth>> show? How did that lead to the idea of skip connections?__\n",
    "\n",
    "The resnet depth graphs shows that more layers does not necessarily yield better results. \n",
    "\n",
    "The 56 layer model has a worse training and testing error compared to the 20 layer model.\n",
    "\n",
    "This led to the idea of starting with a 20 layer network and addding 36 additional layers that do nothing. The 56 layer network should be at least as good as the 20 layer network. \n",
    "\n",
    "But the additional 36 layers have trainable parameters. So there's an (almost) asymmetric risk/reward.\n",
    "\n",
    "The worst that can happen is that the loss is the same as the 20 layer network. The best thing that can happen is that the loss is significantly better than the 20 layer network.\n",
    "\n",
    "The downside  is limited to the original loss of 20 layer network. The upside is unlimited - the loss can be as low as possible. (TODO: maybe rephrase this?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__9. What is \"identity mapping\"?__\n",
    "\n",
    "A mapping that returns the original input matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__10. What is the basic equation for a ResNet block (ignoring batchnorm and ReLU layers)?__\n",
    "\n",
    "`x+conv2(conv1(x))` where `x` is the input tensor. This would be called in the forward function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__11. What do ResNets have to do with residuals?__\n",
    "\n",
    "Resnets are good at detecting the difference between doing nothing and passing a batch through 2 convolutional layers (with trainable weights). This difference can be thought of as the residual (prediction - target)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__12. How do we deal with the skip connection when there is a stride-2 convolution? How about when the number of filters changes?__\n",
    "\n",
    "Stride 2 conv: We use average pooling with a stride of 2. \n",
    "\n",
    "Number of filters changes: We use a conv layer with a kernel size of 1 and our desired number of output filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__13. How can we express a 1Ã—1 convolution in terms of a vector dot product?__\n",
    "\n",
    "It is doing a dot product over the channels of each input pixel. \n",
    "\n",
    "At each cell in the 6x6 matrix below we do the following dot product:\n",
    "\n",
    "$\\begin{pmatrix} r & g & b \\end{pmatrix} . \\begin{pmatrix} y1 \\\\ y2 \\\\ y3 \\end{pmatrix}$ \n",
    "\n",
    "where r, g, b are the cells from the red, green, blue matrices respectively \n",
    "\n",
    "y1, y2, y3 are the cells from the yellow matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://qph.fs.quoracdn.net/main-qimg-3d412cacb0435a8e56eda709ae26795f)\n",
    "\n",
    "from: https://www.quora.com/What-is-a-1X1-convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__14. Create a `1x1 convolution` with `F.conv2d` or `nn.Conv2d` and apply it to an image. What happens to the `shape` of the image?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/pr-newsroom-wp/1/2020/05/IMG_1874-copy-1.jpg # joe rogan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "x = torchvision.transforms.functional.to_tensor(PIL.Image.open('IMG_1874-copy-1.jpg'))\n",
    "x = x[None,:] # add unit axes (represents batch)\n",
    "x.shape\n",
    "# [81]: torch.Size([1, 3, 733, 1920])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_conv = nn.Conv2d(3, 11, kernel_size=1) # 11 output channels randomly chosen\n",
    "y = id_conv(x)\n",
    "y.shape\n",
    "# [82]: torch.Size([1, 11, 733, 1920])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape changes to whatever is designated by the number of channels out. In this case I've picked 11 randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__15. What does the `noop` function return?__\n",
    "\n",
    "The input. It is a function that does nothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__16. Explain what is shown in <<resnet_surface>>__\n",
    "\n",
    "This image shows a regular CNN's loss landscape compared to a ResNet's loss lanscape. The regular CNN has a signficnat number of peaks and valleys. It would be difficult for SGD to navigate this terrain to find the global minimum. \n",
    "\n",
    "On the other hand the ResNet's loss landscape is smooth and has an easy to find minimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__17. When is top-5 accuracy a better metric than top-1 accuracy?__\n",
    "\n",
    "Top-5 accuracy tests how often the label is in the top 5 predictions of the model. It's useful when training with mulitple different objects or objects that are easily confused with one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__18. What is the \"stem\" of a CNN?__\n",
    "\n",
    "The first few layers of the network. The stem will have a different structure than the main body of the CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__19. Why do we use plain convolutions in the CNN stem, instead of ResNet blocks?__\n",
    "\n",
    "The vast majority of computations occur in the early layers. This is because the image size is typically still quite large in the early layers.\n",
    "\n",
    "To speed things up we use plain convolutions in the CNN stem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__20. How does a bottleneck block differ from a plain ResNet block?__\n",
    "\n",
    "A bottleneck block has 3 convolutions. It consists of one 1x1 conv, one 3x3 conv followed by one 1x1. (These are ConvLayers in fastai so there are ReLU's in between each conv). 1x1 convs execute quickly so we can use more filters.\n",
    "\n",
    "A ResNet block has 2 convs. It consists of 2 3x3 convs. The number of filters is fixed over the entire conv.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__21. Why is a bottleneck block faster?__\n",
    "\n",
    "Because we're mainly using 1x1 convs. These have a kernel size of 1 and as a result require fewer computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__22. How do fully convolutional nets (and nets with adaptive pooling in general) allow for progressive resizing?__\n",
    "\n",
    "Adaptive pooling means that the activation map can be converted to a the unit axes (1x1) regardless of size. For example an activation map with dim 4x4 can be converted to the unit axes using Adaptive Average Pooling. This means that images of any size can be fed to the convulutional net. As a result progressive resizing can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
